{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1d1040f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-22T14:44:59.763269Z",
     "iopub.status.busy": "2025-07-22T14:44:59.762984Z",
     "iopub.status.idle": "2025-07-22T14:45:01.550161Z",
     "shell.execute_reply": "2025-07-22T14:45:01.549151Z"
    },
    "papermill": {
     "duration": 1.793252,
     "end_time": "2025-07-22T14:45:01.551834",
     "exception": false,
     "start_time": "2025-07-22T14:44:59.758582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/spaceship-titanic/sample_submission.csv\n",
      "/kaggle/input/spaceship-titanic/train.csv\n",
      "/kaggle/input/spaceship-titanic/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "babe9b31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T14:45:01.559185Z",
     "iopub.status.busy": "2025-07-22T14:45:01.558819Z",
     "iopub.status.idle": "2025-07-22T14:45:01.618667Z",
     "shell.execute_reply": "2025-07-22T14:45:01.617923Z"
    },
    "papermill": {
     "duration": 0.06493,
     "end_time": "2025-07-22T14:45:01.620229",
     "exception": false,
     "start_time": "2025-07-22T14:45:01.555299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Leer archivo cvs y poner en df\n",
    "df = pd.read_csv(\"/kaggle/input/spaceship-titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f412605",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T14:45:01.627024Z",
     "iopub.status.busy": "2025-07-22T14:45:01.626469Z",
     "iopub.status.idle": "2025-07-22T14:45:01.762047Z",
     "shell.execute_reply": "2025-07-22T14:45:01.761111Z"
    },
    "papermill": {
     "duration": 0.140625,
     "end_time": "2025-07-22T14:45:01.763731",
     "exception": false,
     "start_time": "2025-07-22T14:45:01.623106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear una pipeline para el data wrangling\n",
    "# Se salva el PassengerId que es el índice\n",
    "index = df['PassengerId']\n",
    "# Se desglosan en nuevas columnas tanto PassengerId como Cabin\n",
    "df[['Group', 'NumberGroup']] = df['PassengerId'].str.split('_', expand=True)\n",
    "df[['Deck', 'Num', \"Side\"]] = df['Cabin'].str.split('/', expand=True)\n",
    "# Se suprimen las variables que son redundantes\n",
    "df = df.drop(['PassengerId','Cabin',\"NumberGroup\",\"Name\"], axis = 1)\n",
    "df[\"Num\"] = df[\"Num\"].astype(float).round(0)\n",
    "df[\"Group\"] = df[\"Group\"].astype(float).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f35f81a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T14:45:01.770445Z",
     "iopub.status.busy": "2025-07-22T14:45:01.770159Z",
     "iopub.status.idle": "2025-07-22T14:45:01.843651Z",
     "shell.execute_reply": "2025-07-22T14:45:01.842751Z"
    },
    "papermill": {
     "duration": 0.078651,
     "end_time": "2025-07-22T14:45:01.845244",
     "exception": false,
     "start_time": "2025-07-22T14:45:01.766593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Group</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Num</th>\n",
       "      <th>Side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8492</td>\n",
       "      <td>8476</td>\n",
       "      <td>8511</td>\n",
       "      <td>8514.000000</td>\n",
       "      <td>8490</td>\n",
       "      <td>8512.000000</td>\n",
       "      <td>8510.000000</td>\n",
       "      <td>8485.000000</td>\n",
       "      <td>8510.000000</td>\n",
       "      <td>8505.000000</td>\n",
       "      <td>8693</td>\n",
       "      <td>8693.000000</td>\n",
       "      <td>8494</td>\n",
       "      <td>8494.000000</td>\n",
       "      <td>8494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4602</td>\n",
       "      <td>5439</td>\n",
       "      <td>5915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.827930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>224.687617</td>\n",
       "      <td>458.077203</td>\n",
       "      <td>173.729169</td>\n",
       "      <td>311.138778</td>\n",
       "      <td>304.854791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4633.389624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600.367671</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.489021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>666.717663</td>\n",
       "      <td>1611.489240</td>\n",
       "      <td>604.696458</td>\n",
       "      <td>1136.705535</td>\n",
       "      <td>1145.717189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2671.028856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>511.867226</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2319.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.250000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4630.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6883.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14327.000000</td>\n",
       "      <td>29813.000000</td>\n",
       "      <td>23492.000000</td>\n",
       "      <td>22408.000000</td>\n",
       "      <td>24133.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9280.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1894.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HomePlanet CryoSleep  Destination          Age    VIP   RoomService  \\\n",
       "count        8492      8476         8511  8514.000000   8490   8512.000000   \n",
       "unique          3         2            3          NaN      2           NaN   \n",
       "top         Earth     False  TRAPPIST-1e          NaN  False           NaN   \n",
       "freq         4602      5439         5915          NaN   8291           NaN   \n",
       "mean          NaN       NaN          NaN    28.827930    NaN    224.687617   \n",
       "std           NaN       NaN          NaN    14.489021    NaN    666.717663   \n",
       "min           NaN       NaN          NaN     0.000000    NaN      0.000000   \n",
       "25%           NaN       NaN          NaN    19.000000    NaN      0.000000   \n",
       "50%           NaN       NaN          NaN    27.000000    NaN      0.000000   \n",
       "75%           NaN       NaN          NaN    38.000000    NaN     47.000000   \n",
       "max           NaN       NaN          NaN    79.000000    NaN  14327.000000   \n",
       "\n",
       "           FoodCourt  ShoppingMall           Spa        VRDeck Transported  \\\n",
       "count    8510.000000   8485.000000   8510.000000   8505.000000        8693   \n",
       "unique           NaN           NaN           NaN           NaN           2   \n",
       "top              NaN           NaN           NaN           NaN        True   \n",
       "freq             NaN           NaN           NaN           NaN        4378   \n",
       "mean      458.077203    173.729169    311.138778    304.854791         NaN   \n",
       "std      1611.489240    604.696458   1136.705535   1145.717189         NaN   \n",
       "min         0.000000      0.000000      0.000000      0.000000         NaN   \n",
       "25%         0.000000      0.000000      0.000000      0.000000         NaN   \n",
       "50%         0.000000      0.000000      0.000000      0.000000         NaN   \n",
       "75%        76.000000     27.000000     59.000000     46.000000         NaN   \n",
       "max     29813.000000  23492.000000  22408.000000  24133.000000         NaN   \n",
       "\n",
       "              Group  Deck          Num  Side  \n",
       "count   8693.000000  8494  8494.000000  8494  \n",
       "unique          NaN     8          NaN     2  \n",
       "top             NaN     F          NaN     S  \n",
       "freq            NaN  2794          NaN  4288  \n",
       "mean    4633.389624   NaN   600.367671   NaN  \n",
       "std     2671.028856   NaN   511.867226   NaN  \n",
       "min        1.000000   NaN     0.000000   NaN  \n",
       "25%     2319.000000   NaN   167.250000   NaN  \n",
       "50%     4630.000000   NaN   427.000000   NaN  \n",
       "75%     6883.000000   NaN   999.000000   NaN  \n",
       "max     9280.000000   NaN  1894.000000   NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43edb773",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T14:45:01.852580Z",
     "iopub.status.busy": "2025-07-22T14:45:01.852209Z",
     "iopub.status.idle": "2025-07-22T14:45:01.879885Z",
     "shell.execute_reply": "2025-07-22T14:45:01.878915Z"
    },
    "papermill": {
     "duration": 0.03301,
     "end_time": "2025-07-22T14:45:01.881387",
     "exception": false,
     "start_time": "2025-07-22T14:45:01.848377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HomePlanet_Earth               0\n",
       "HomePlanet_Europa              0\n",
       "HomePlanet_Mars                0\n",
       "CryoSleep_False                0\n",
       "CryoSleep_True                 0\n",
       "Destination_55 Cancri e        0\n",
       "Destination_PSO J318.5-22      0\n",
       "Destination_TRAPPIST-1e        0\n",
       "Age                          179\n",
       "VIP_False                      0\n",
       "VIP_True                       0\n",
       "RoomService                  181\n",
       "FoodCourt                    183\n",
       "ShoppingMall                 208\n",
       "Spa                          183\n",
       "VRDeck                       188\n",
       "Transported                    0\n",
       "Group                          0\n",
       "Deck_A                         0\n",
       "Deck_B                         0\n",
       "Deck_C                         0\n",
       "Deck_D                         0\n",
       "Deck_E                         0\n",
       "Deck_F                         0\n",
       "Deck_G                         0\n",
       "Deck_T                         0\n",
       "Num                          199\n",
       "Side_P                         0\n",
       "Side_S                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se hace la transformacion scaler y one hot encoding\n",
    "dummies = pd.DataFrame()\n",
    "for col in df:\n",
    "    if df[col].dtype == \"object\":  # Si la columna es de tipo object (categórica)\n",
    "        # Crear columnas dummy para la columna categórica\n",
    "        dummy_cols = pd.get_dummies(df[col], prefix=col)\n",
    "        # Concatenar las columnas dummy al DataFrame dummies\n",
    "        dummies = pd.concat([dummies, dummy_cols], axis=1)\n",
    "    else:  # Si la columna no es de tipo object, agregarla tal cual al DataFrame de dummies\n",
    "        dummies[col] = df[col]\n",
    "\n",
    "df = dummies\n",
    "\n",
    "# Se buscan la cantidad de datos ausentes\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7b57990",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T14:45:01.889051Z",
     "iopub.status.busy": "2025-07-22T14:45:01.888753Z",
     "iopub.status.idle": "2025-07-22T14:45:33.343286Z",
     "shell.execute_reply": "2025-07-22T14:45:33.342342Z"
    },
    "papermill": {
     "duration": 31.462849,
     "end_time": "2025-07-22T14:45:33.347552",
     "exception": false,
     "start_time": "2025-07-22T14:45:01.884703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 1\n",
      "Iteración 2\n",
      "Iteración 3\n",
      "Iteración 4\n",
      "Iteración 5\n",
      "Imputación completada.\n"
     ]
    }
   ],
   "source": [
    "# La idea es imputar los ausentes con un loop con randomforest\n",
    "# Iterar sobre las columnas del DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "df_imputado = df.copy()\n",
    "max_iter = 5  # Número máximo de vueltas por si queda atascado\n",
    "i = 0\n",
    "\n",
    "while df_imputado.isnull().sum().sum() > 0 and i < max_iter:\n",
    "    print(f\"Iteración {i+1}\")\n",
    "    for col in df_imputado.columns:\n",
    "        if df_imputado[col].isnull().sum() == 0:\n",
    "            continue\n",
    "\n",
    "        # Separar filas donde col NO es NaN\n",
    "        train_data = df_imputado[df_imputado[col].notnull()]\n",
    "        X_train = train_data.drop(columns=[col])\n",
    "        y_train = train_data[col]\n",
    "\n",
    "        # Eliminar filas con NaN en X_train\n",
    "        train_mask = X_train.notnull().all(axis=1)\n",
    "        X_train = X_train[train_mask]\n",
    "        y_train = y_train[train_mask]\n",
    "\n",
    "        # Separar filas donde col ES NaN\n",
    "        test_data = df_imputado[df_imputado[col].isnull()]\n",
    "        X_test = test_data.drop(columns=[col])\n",
    "\n",
    "        # Eliminar filas con NaN en X_test\n",
    "        X_test_clean = X_test[X_test.notnull().all(axis=1)]\n",
    "        valid_indices = X_test_clean.index\n",
    "\n",
    "        if len(valid_indices) == 0:\n",
    "            continue\n",
    "\n",
    "        # Elegir modelo según tipo de dato\n",
    "        if y_train.dtype == 'object' or y_train.dtype == 'bool':\n",
    "            model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "        else:\n",
    "            model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "        # Entrenar y predecir\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test_clean)\n",
    "\n",
    "        # Conversión si es bool o categórica\n",
    "        if y_train.dtype == 'bool':\n",
    "            y_pred = y_pred.astype(bool)\n",
    "        elif y_train.dtype == 'object':\n",
    "            y_pred = pd.Series(y_pred).astype(df_imputado[col].dtype).values\n",
    "\n",
    "        # Imputar\n",
    "        df_imputado.loc[valid_indices, col] = y_pred\n",
    "\n",
    "    i += 1\n",
    "\n",
    "print(\"Imputación completada.\")\n",
    "# Se eliminan los NAN que hayan quedado\n",
    "df = df_imputado.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "616c1df3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T14:45:33.355603Z",
     "iopub.status.busy": "2025-07-22T14:45:33.355136Z",
     "iopub.status.idle": "2025-07-22T14:51:12.073923Z",
     "shell.execute_reply": "2025-07-22T14:51:12.072984Z"
    },
    "papermill": {
     "duration": 338.728257,
     "end_time": "2025-07-22T14:51:12.079230",
     "exception": false,
     "start_time": "2025-07-22T14:45:33.350973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Mejores hiperparámetros: {'bootstrap': True, 'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Mejor score CV: 0.783536231884058\n"
     ]
    }
   ],
   "source": [
    "# Preparamos conjunto de train\n",
    "X_train = df.drop([\"Transported\"], axis=1)\n",
    "y_train = df[\"Transported\"]\n",
    "\n",
    "# Entrenamos el modelo clasificador\n",
    "\n",
    "# Definir el modelo base\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Definir el espacio de búsqueda de hiperparámetros\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300],       # Número de árboles\n",
    "    'max_depth': [10, 20],      # Profundidad máxima del árbol\n",
    "    'min_samples_split': [2, 5, 10],      # Min muestras para dividir nodo\n",
    "    'min_samples_leaf': [1, 2, 4],        # Min muestras en hoja\n",
    "    'bootstrap': [True, False]             # Método de muestreo para árboles\n",
    "}\n",
    "\n",
    "# Crear el objeto GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,               # Número de folds para cross-validation\n",
    "    n_jobs=-1,          # Usar todos los núcleos disponibles\n",
    "    verbose=1           # Mostrar progreso\n",
    ")\n",
    "\n",
    "# Ajustar (entrenar) con los datos\n",
    "best_model = grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Resultados\n",
    "print(\"Mejores hiperparámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor score CV:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a215e537",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T14:51:12.087415Z",
     "iopub.status.busy": "2025-07-22T14:51:12.087098Z",
     "iopub.status.idle": "2025-07-22T14:51:24.086348Z",
     "shell.execute_reply": "2025-07-22T14:51:24.085382Z"
    },
    "papermill": {
     "duration": 12.00515,
     "end_time": "2025-07-22T14:51:24.087866",
     "exception": false,
     "start_time": "2025-07-22T14:51:12.082716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4277, 13)\n",
      "Iteración 1\n",
      "Iteración 2\n",
      "Iteración 3\n",
      "Iteración 4\n",
      "Iteración 5\n",
      "Imputación completada.\n"
     ]
    }
   ],
   "source": [
    "# Se carga el archivo de test y se realizan las transformaciones\n",
    "df = pd.read_csv(\"/kaggle/input/spaceship-titanic/test.csv\")\n",
    "print(df.shape)\n",
    "index = df['PassengerId']\n",
    "# Se desglosan en nuevas columnas tanto PassengerId como Cabin\n",
    "df[['Group', 'NumberGroup']] = df['PassengerId'].str.split('_', expand=True)\n",
    "df[['Deck', 'Num', \"Side\"]] = df['Cabin'].str.split('/', expand=True)\n",
    "# Se suprimen las variables que son redundantes\n",
    "df = df.drop(['PassengerId','Cabin',\"NumberGroup\",\"Name\"], axis = 1)\n",
    "df[\"Num\"] = df[\"Num\"].astype(float).round(0)\n",
    "df[\"Group\"] = df[\"Group\"].astype(float).round(0)\n",
    "dummies = pd.DataFrame()\n",
    "for col in df:\n",
    "    if df[col].dtype == \"object\":  # Si la columna es de tipo object (categórica)\n",
    "        # Crear columnas dummy para la columna categórica\n",
    "        dummy_cols = pd.get_dummies(df[col], prefix=col)\n",
    "        # Concatenar las columnas dummy al DataFrame dummies\n",
    "        dummies = pd.concat([dummies, dummy_cols], axis=1)\n",
    "    else:  # Si la columna no es de tipo object, agregarla tal cual al DataFrame de dummies\n",
    "        dummies[col] = df[col]\n",
    "\n",
    "df = dummies\n",
    "df_imputado = df.copy()\n",
    "# Imputamos a mano la edad\n",
    "age_mean = df_imputado[\"Age\"].mean()\n",
    "df_imputado[\"Age\"] = df[\"Age\"].fillna(age_mean)\n",
    "\n",
    "max_iter = 5  # Número máximo de vueltas por si queda atascado\n",
    "i = 0\n",
    "\n",
    "while df_imputado.isnull().sum().sum() > 0 and i < max_iter:\n",
    "    print(f\"Iteración {i+1}\")\n",
    "    for col in df_imputado.columns:\n",
    "        if df_imputado[col].isnull().sum() == 0:\n",
    "            continue\n",
    "\n",
    "        # Separar filas donde col NO es NaN\n",
    "        train_data = df_imputado[df_imputado[col].notnull()]\n",
    "        X_train = train_data.drop(columns=[col])\n",
    "        y_train = train_data[col]\n",
    "\n",
    "        # Eliminar filas con NaN en X_train\n",
    "        train_mask = X_train.notnull().all(axis=1)\n",
    "        X_train = X_train[train_mask]\n",
    "        y_train = y_train[train_mask]\n",
    "\n",
    "        # Separar filas donde col ES NaN\n",
    "        test_data = df_imputado[df_imputado[col].isnull()]\n",
    "        X_test = test_data.drop(columns=[col])\n",
    "\n",
    "        # Eliminar filas con NaN en X_test\n",
    "        X_test_clean = X_test[X_test.notnull().all(axis=1)]\n",
    "        valid_indices = X_test_clean.index\n",
    "\n",
    "        if len(valid_indices) == 0:\n",
    "            continue\n",
    "\n",
    "        # Elegir modelo según tipo de dato\n",
    "        if y_train.dtype == 'object' or y_train.dtype == 'bool':\n",
    "            model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "        else:\n",
    "            model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "        # Entrenar y predecir\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test_clean)\n",
    "\n",
    "        # Conversión si es bool o categórica\n",
    "        if y_train.dtype == 'bool':\n",
    "            y_pred = y_pred.astype(bool)\n",
    "        elif y_train.dtype == 'object':\n",
    "            y_pred = pd.Series(y_pred).astype(df_imputado[col].dtype).values\n",
    "\n",
    "        # Imputar\n",
    "        df_imputado.loc[valid_indices, col] = y_pred\n",
    "\n",
    "    i += 1\n",
    "\n",
    "print(\"Imputación completada.\")\n",
    "df = df_imputado\n",
    "\n",
    "# Los NaN que quedan los cambiamos por su media\n",
    "df = df.fillna(df.mean(numeric_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2f67c98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T14:51:24.096192Z",
     "iopub.status.busy": "2025-07-22T14:51:24.095904Z",
     "iopub.status.idle": "2025-07-22T14:51:24.315079Z",
     "shell.execute_reply": "2025-07-22T14:51:24.314233Z"
    },
    "papermill": {
     "duration": 0.225161,
     "end_time": "2025-07-22T14:51:24.316770",
     "exception": false,
     "start_time": "2025-07-22T14:51:24.091609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preparamos X_test\n",
    "X_test = df\n",
    "\n",
    "# Hacemos la prediccion\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Se une la prediccion con los passengerIds\n",
    "submit = pd.DataFrame({\n",
    "    \"PassengerId\": index,       # Asegurate de tener esta columna\n",
    "    \"Transported\": y_pred\n",
    "})\n",
    "\n",
    "submit\n",
    "submit.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcc4f25",
   "metadata": {
    "papermill": {
     "duration": 0.003206,
     "end_time": "2025-07-22T14:51:24.323574",
     "exception": false,
     "start_time": "2025-07-22T14:51:24.320368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 3220602,
     "sourceId": 34377,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 391.8646,
   "end_time": "2025-07-22T14:51:26.947550",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-22T14:44:55.082950",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
